Lab 12 (Decision Trees)

Instructions:
a. Load Dataset 'Iris (5).csv'
b. Drop unwanted columns that will not contribute to the prediction of 'Species'
c. There are missing 'Species' data in the dataset with 'NaN' at index 150 to 157
   Replace them scientifically based on existing data.
   It is better to check the closest (probable) values, this is crucial for the correct answer onwards.
   You are on you own with this one, replace the missing 'Species' (NaN) values based on the mean features by grouping (groupby) 'Species' and finding its mean (.mean())
   Replace missing 'Species' of data 150 to 157 from your corresponding analysis by using df.at[index, column] = ['Species Values']

   Example: df.at[150, 'Species'] = 'Iris-Setosa'

d. Where applicable, use random_state = 50 for the model itself and for train_test_split
e. Test size = 0.3


Questions (Write on Paper):

1. 	What is the accuracy of the Decision Tree model based on classification report?
2. 	What is the Species on if I have [4.95, 2.9, 1.3, 0.1]
3. 	What is the Species on if I have [2.45, 3.9, 2.5, 0.2]
4.	What is the most important variable in the dataset for prediction?
5.      How many terminal nodes from your generated Decision Tree?

--x--x--x--x---x

Lab 13 (Support Vector Machines)

Instructions:
a. Load Dataset 'Iris (5).csv'
b. Drop unwanted columns that will not contribute to the prediction of 'Species'
c. There are missing 'Species' data in the dataset with 'NaN'.
   Replace them scientifically based on existing data.
   It is better to check the closes (probable) values, this is crucial for the correct answer onwards.
   You are on you own with this one, replace the missing 'Species' (NaN) values based on the mean features by grouping 'Species' and finding its mean
   Replace missing 'Species' of data 150 to 157 from your corresponding analysis by using df.at[index, column] = ['Species Values']

d. Validation data = [[3.15, 3.2, 1.21, 0.2, 'Unknown'],
                     [1.35, 4.1, 1.7, 0.2], 'Unknown']
e. Since we are using SVM, you need to use StandardScaler to normalize the dataset
f. Remove the validation data from the dataset before training
d. Where applicable, use random_state = 101 for the model itself and for train_test_split
e. Test size = 0.3

Questions (Write on Paper):

6. What is the the best model based on grid search with the following values:
   {'C': [0.01, 0.05, 0.1, 0.5, 1, 1.5, 3, 5, 10, 25, 50, 100], 'kernel': ['linear', 'rbf', 'poly']}

   Sample answer: C = 3.5, kernel = 'poly'

7. Using the best parameter, what is the accuracy of the SVM model?
8. What is the True Positive value based on the confusion matrix of the best model?
9. What is the 'Species' for validation data number 1?
10. What is the 'Species' for validation data number 2?

(Send two separate notebooks to renatomaaliw3@yahoo.com)







