{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Web Data Scraping\n",
        "\n",
        "__Web Data Scraping__ is a technique used to extract data from websites. This process involves programmatically accessing web pages and pulling out the information that you need. Web scraping can be used to gather data from websites that do not provide an __*Application Program Interface (API)*__ for easy data access or when you need large amounts of data quickly and the site's API limits do not allow for this. Here are the key aspects of web scraping:\n",
        "\n",
        "1. __Sending a Request:__ The first step is to send a request to the web server hosting the website from which data is to be scraped. This request is typically done using HTTP or HTTPS protocols.\n",
        "\n",
        "2. __Receiving the Response:__ The server responds to the request by sending back the requested web page, often in HTML format. Other formats like JSON and XML can also be received depending on the API or web service.\n",
        "\n",
        "3. __Parsing the Data:__ Once the data is received, it needs to be parsed. For HTML, this usually involves using libraries like BeautifulSoup in Python, which allow for easy navigation of the structure of the HTML and extraction of the relevant information.\n",
        "\n",
        "4. __Data Extraction:__ After parsing, the necessary data is extracted. This could be anything from product details on an ecommerce site, stock prices, sports statistics, or any other information available on the web."
      ],
      "metadata": {
        "id": "tqT1S5bhXyrH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "0DcD7Z8Bnz4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "F3DzubOt_57l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BeautifulSoup Methods (Common)\n",
        "\n",
        "\n",
        "| Method                  | Description                                      |\n",
        "|-------------------------|--------------------------------------------------|\n",
        "| `.find()`               | Finds the **first** matching element             |\n",
        "| `.find_all()`          | Finds **all** matching elements                  |\n",
        "| `.find_next()`         | Finds the **next** matching element              |\n",
        "| `.find_previous()`     | Finds the **previous** matching element          |\n",
        "| `.find_next_sibling()` | Finds the **next** sibling element               |\n",
        "| `.find_previous_sibling()` | Finds the **previous** sibling element       |\n",
        "| `.find_parents()`      | Finds **all** parent elements                    |\n",
        "| `.find_parent()`       | Finds the **direct** parent element              |\n",
        "| `.get_text()`          | Extracts text inside a tag                       |\n",
        "| `.decompose()`         | Removes an element from the HTML                 |\n",
        "| `.replace_with()`      | Replaces an element with new content             |\n",
        "| `.select()`           | Finds **multiple** elements using CSS selectors  |\n",
        "| `.select_one()`       | Finds the **first** element using CSS selectors  |\n",
        "| `.get()`             | Retrieves an **attribute value**                   |\n",
        "| `.has_attr()`         | Checks if an element has an **attribute**         |"
      ],
      "metadata": {
        "id": "q_57EAhIxdP6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Web Scrape Basic Demo"
      ],
      "metadata": {
        "id": "0-8vFfKv5qGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Link to URL\n",
        "\n",
        "url = 'https://renatomaaliw3.github.io/scrape_demo.html'"
      ],
      "metadata": {
        "id": "NN2oTB_BjApM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Send requests\n",
        "\n",
        "# When you're making HTTP requests for web scraping, many websites check the \"User-Agent\" header\n",
        "# to see what kind of client is making the request.\n",
        "# By setting this header, you can mimic a real browser, which can help avoid blocks\n",
        "# or serve the correct content.\n",
        "\n",
        "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36'}"
      ],
      "metadata": {
        "id": "lZ2Zum9ajH8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Response\n",
        "\n",
        "# This is a function from the requests library that makes an HTTP GET request.\n",
        "# GET requests are used to retrieve data from a specified resource.\n",
        "\n",
        "response = requests.get(url = url, headers = headers)"
      ],
      "metadata": {
        "id": "irUsnKUSjKTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bs4 object to parse the HTML content\n",
        "\n",
        "# This contains the raw bytes of the HTML content returned by your requests.get() call.\n",
        "# Using .content ensures that you get the raw data, which is useful for parsing.\n",
        "\n",
        "# This tells BeautifulSoup to parse the HTML using Pythonâ€™s built-in HTML parser.\n",
        "# The parser converts the raw HTML into a structured format (a parse tree) that you\n",
        "# can easily navigate and search with methods like .find(), .find_all(), and .select().\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')"
      ],
      "metadata": {
        "id": "ES2XsmbVjM8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# .find()\n",
        "\n",
        "# output = soup.find('table')\n",
        "# output = soup.find('table', id = 'table-2')\n",
        "# output = soup.find('td', class_ = 'vip')\n",
        "output = soup.find('td', attrs = {'data-occupation': 'ceo'})\n",
        "\n",
        "output"
      ],
      "metadata": {
        "id": "zOo59vVZQCjI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba6760be-a1d4-444a-a8b9-0d5238bab0b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<td data-occupation=\"ceo\">Ariel Buckner</td>"
            ]
          },
          "metadata": {},
          "execution_count": 338
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .find_all()\n",
        "\n",
        "# output = soup.find_all('th')\n",
        "# output = soup.find_all('th', class_ = 'name') # or used attrs\n",
        "\n",
        "# target_ol = soup.find('ol', class_ = 'list level2')\n",
        "# output = target_ol.find_all('span', recursive = False)\n",
        "\n",
        "# target_ol = soup.find('ol', class_ = 'list level1')\n",
        "# output = target_ol.find_all('span', string = ' LEVEL 2 ')\n",
        "\n",
        "# import re\n",
        "# target_ol = soup.find('ol', class_ = 'list level1')\n",
        "# output = target_ol.find_all('span', string = re.compile('LEVEL 2'))\n",
        "\n",
        "# target_ol = soup.find('ol', class_ = 'list level1')\n",
        "# output = target_ol.find_all('ol', class_ = 'list level3', limit = 2)\n",
        "\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9GqbZX_mSLq",
        "outputId": "c6a4868c-84a5-421c-bfaa-31a3bcec27df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<td data-occupation=\"ceo\">Ariel Buckner</td>"
            ]
          },
          "metadata": {},
          "execution_count": 339
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .select()\n",
        "\n",
        "# output = soup.select('ol')\n",
        "# output = soup.select('li > span')\n",
        "# output = soup.select('li#item-304')\n",
        "# output = soup.select('ol#list-837 li > span.red')\n",
        "# output = soup.select('li', attrs = {'data-code': 'E5F6'})\n",
        "# output = soup.select('ol.list.level3 > li:first-child')\n",
        "# output = soup.select('span[class =\"link red\"]')\n",
        "\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owEjyJ0rq-E9",
        "outputId": "9c0d81fb-a633-4ac3-8ac2-ead530e21a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<td data-occupation=\"ceo\">Ariel Buckner</td>"
            ]
          },
          "metadata": {},
          "execution_count": 340
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .select_one()\n",
        "\n",
        "# output = soup.select_one('ol.list.level3 > li')\n",
        "# output = soup.select_one('ol span')\n",
        "# output = soup.select_one('table span')\n",
        "\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLT_JfhZu9n8",
        "outputId": "a004b9dd-d5e8-4699-ca4e-9e9def0d8e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<td data-occupation=\"ceo\">Ariel Buckner</td>"
            ]
          },
          "metadata": {},
          "execution_count": 341
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .children()\n",
        "\n",
        "ol_list_level3 = soup.find('ol', class_ = 'list level3')\n",
        "\n",
        "for child in ol_list_level3.children:\n",
        "\n",
        "  print(child)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HgZo7yjxTYV",
        "outputId": "66482d26-1344-4066-f7d3-bcbfc9329035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "<li class=\"entry gamma\" data-code=\"C3D4\" id=\"item-867\">\n",
            "<span class=\"link green\"> Third Level A.1 </span>\n",
            "</li>\n",
            "\n",
            "\n",
            "<li class=\"entry delta\" data-code=\"E5F6\" id=\"item-145\">\n",
            "<span class=\"link purple\"> Third Level A.2 </span>\n",
            "</li>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .descendants()\n",
        "\n",
        "ol_list_level3 = soup.find('ol', class_ = 'list level3')\n",
        "\n",
        "for child in ol_list_level3.descendants:\n",
        "\n",
        "  print(child)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tY_oD5HXyFiI",
        "outputId": "9298dbca-adef-497e-ab4d-ee99a832be9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "<li class=\"entry gamma\" data-code=\"C3D4\" id=\"item-867\">\n",
            "<span class=\"link green\"> Third Level A.1 </span>\n",
            "</li>\n",
            "\n",
            "\n",
            "<span class=\"link green\"> Third Level A.1 </span>\n",
            " Third Level A.1 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "<li class=\"entry delta\" data-code=\"E5F6\" id=\"item-145\">\n",
            "<span class=\"link purple\"> Third Level A.2 </span>\n",
            "</li>\n",
            "\n",
            "\n",
            "<span class=\"link purple\"> Third Level A.2 </span>\n",
            " Third Level A.2 \n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .find_next_sibling()\n",
        "\n",
        "table_1 = soup.select_one('table#table-1')\n",
        "th_name = table_1.find('th', class_ = 'name')\n",
        "next_sib = th_name.find_next_sibling()\n",
        "\n",
        "next_sib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5HcdcCDyvSE",
        "outputId": "37c9ea91-6a47-4bff-c61b-4d1a30bdd51f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<th class=\"email\"> Email </th>"
            ]
          },
          "metadata": {},
          "execution_count": 344
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .find_previous_sibling()\n",
        "\n",
        "table_1 = soup.select_one('table#table-1')\n",
        "th_name = table_1.find('th', class_ = 'email')\n",
        "next_sib = th_name.find_previous_sibling('th')\n",
        "\n",
        "next_sib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC6MLMnu0bnk",
        "outputId": "01671249-b680-414f-c972-79ff4b4fe327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<th class=\"name\"> Name </th>"
            ]
          },
          "metadata": {},
          "execution_count": 345
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .get_text()\n",
        "\n",
        "table_1 = soup.select_one('table#table-1')\n",
        "th_name = table_1.find('th', class_ = 'name')\n",
        "th_name.get_text().strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qX-OYZ431G6T",
        "outputId": "e58d4731-6354-42ed-8264-44a0d9568bbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Name'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 346
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .get_text() - long method\n",
        "\n",
        "data = []\n",
        "table_rows = soup.select('table#table-1 > tr')[1:]\n",
        "\n",
        "for row in table_rows:\n",
        "\n",
        "  cols = []\n",
        "  tds = row.find_all('td')\n",
        "\n",
        "  for td in tds:\n",
        "\n",
        "    text = td.get_text()\n",
        "    cols.append(text)\n",
        "\n",
        "  data.append(cols)\n",
        "\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fx08NbK5bHe",
        "outputId": "c1e6707c-2817-442a-e1de-aede601184e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[\"Geoffrey O'Donnell\", 'vitae.semper@protonmail.org', 'Nigeria', 'Flevoland'],\n",
              " ['Justin Patrick', 'orci.ut.sagittis@outlook.com', 'Peru', 'Punjab'],\n",
              " ['Ariel Buckner', 'nunc@google.net', 'Vietnam', 'North Chungcheong'],\n",
              " ['Imani Faulkner', 'hendrerit@yahoo.com', 'Philippines', 'Bicol'],\n",
              " ['Colorado Hampton', 'eros.nam@hotmail.couk', 'Brazil', 'Katsina']]"
            ]
          },
          "metadata": {},
          "execution_count": 347
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .get_text() - recommended\n",
        "\n",
        "data = []\n",
        "table_rows = soup.select('table#table-1 > tr')[1:]\n",
        "\n",
        "for row in table_rows:\n",
        "\n",
        "  cols = [col.get_text(strip = True) for col in row.find_all('td')]\n",
        "  data.append(cols)\n",
        "\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_yO8x538bg8",
        "outputId": "099086d5-e389-4a19-f94c-9df0562fc61f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[\"Geoffrey O'Donnell\", 'vitae.semper@protonmail.org', 'Nigeria', 'Flevoland'],\n",
              " ['Justin Patrick', 'orci.ut.sagittis@outlook.com', 'Peru', 'Punjab'],\n",
              " ['Ariel Buckner', 'nunc@google.net', 'Vietnam', 'North Chungcheong'],\n",
              " ['Imani Faulkner', 'hendrerit@yahoo.com', 'Philippines', 'Bicol'],\n",
              " ['Colorado Hampton', 'eros.nam@hotmail.couk', 'Brazil', 'Katsina']]"
            ]
          },
          "metadata": {},
          "execution_count": 348
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .attrs\n",
        "\n",
        "div_tag = soup.find('li', id = 'item-592')\n",
        "div_tag.attrs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kptBD74-0u8",
        "outputId": "98274278-3d99-4f2e-ae99-249e3f749cb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'item-592', 'class': ['entry', 'alpha'], 'data-code': 'X7Z3'}"
            ]
          },
          "metadata": {},
          "execution_count": 349
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample scenario\n",
        "\n",
        "if (div_tag.attrs.get('class')[0] == 'entry'):\n",
        "\n",
        "  print(True)\n",
        "\n",
        "else:\n",
        "\n",
        "  print(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TJOZgdCCmEN",
        "outputId": "96bb307d-c2f0-4bc0-9100-38a64fb828ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample scenario (in)\n",
        "\n",
        "classes = div_tag.attrs.get('class')\n",
        "\n",
        "if ('entry' in classes and 'alpha' in classes):\n",
        "\n",
        "  print(True)\n",
        "\n",
        "else:\n",
        "\n",
        "  print(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8hTDkmNCtoN",
        "outputId": "82e8632b-3f78-4d78-8f2a-6033b5f29b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample scenario (set)\n",
        "\n",
        "\n",
        "if (set(div_tag.attrs.get('class')) == {'entry', 'alpha'}):\n",
        "\n",
        "  print(True)\n",
        "\n",
        "else:\n",
        "\n",
        "  print(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MsWGzNaDFAs",
        "outputId": "d1c1aafe-7f5f-4337-cb4d-e2e975752893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .get\n",
        "\n",
        "div_tag = soup.find('li', id = 'item-592')\n",
        "div_tag.get('data-code')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NaOLNrRT_WsU",
        "outputId": "52a77820-b9e5-44a3-b579-84467b31d0ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'X7Z3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 353
        }
      ]
    }
  ]
}